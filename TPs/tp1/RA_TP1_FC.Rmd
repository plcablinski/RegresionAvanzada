---
title: "RA_TP1"
author: "Fernando Coz"
date: "2023-06-01"
output: html_document
---

## Inicio

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C://Austral/mcd-reg-adv")
```

```{r}
rm( list = ls(all.names = TRUE) )
gc( full = TRUE )
```

## Librerias

```{r}
suppressMessages( library(ggpmisc) )
suppressMessages( library(readxl) )
suppressMessages( library(MVN) )
```

## Funciones

```{r}

test_supuestos <- function( my_model, nivel_significancia = 0.05 ) {
  
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
  
  #Shapiro Test
  t_sha <- shapiro.test( my_model$residuals )
  t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
                       "Los residuos son normales.",
                       "Los residuos NO son normales.")
  
  #BP Test
  t_bp <- bptest( my_model )
  t_bp_obs <- ifelse( unname(t_bp$p.value) > nivel_significancia,
                     "Homocedasticidad. La varianza de los residuos es constante.",
                     "Heterocedasticidad. La varianza de los residuos NO es constante.")
  
  #Durbin-Watson Test
  #ifelse( t_dwt$dw > 1.5 && t_dwt$dw < 2.5,
  t_dwt <- durbinWatsonTest( my_model )
  t_dwt_obs <- ifelse( t_dwt$p > nivel_significancia,
                      "No hay autocorrelación. Los residuos son independientes.",
                      "Hay autocorrelación. Los residuos NO son independientes.")
  
  resultados <- data.frame(
    Prueba = c("Shapiro", "Breusch-Pagan", "Durbin-Watson"),
    P_Value = c(t_sha$p.value, unname(t_bp$p.value), t_dwt$p)
  )
  
  resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
  resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs,
                                     ifelse( resultados$Prueba == "Breusch-Pagan", t_bp_obs, t_dwt_obs ) )

return(resultados)
}
```

## Resolución

## Ejercicio 1.1

### Dataset

```{r}
g_cerdos <- read_excel("./datasets/grasacerdos.xlsx") 
```

### a) Diagrama de dispersión

```{r}
#Calculo la media muestral de cada una de las variables
u_PV <- mean(g_cerdos$PV)
u_EGD <- mean(g_cerdos$EGD)
```

```{r}
ggplot( data = g_cerdos, aes( x = PV, y = EGD ) ) +
  geom_point( colour = "red4", size = 2) +
  ggtitle( "Peso Vivo (Kg) vs Espesor Grasa Dorsal (mm)" ) +
  theme_bw() + 
  theme( plot.title = element_text( hjust = 0.5 ) ) +
  geom_vhlines( xintercept = u_PV, yintercept = u_EGD, linetype = "dashed")
  
```

```{r}
#Puedo también contabilizar la cantidad de puntos por cuadrante

x_sup <- g_cerdos$PV > u_PV
y_sup <- g_cerdos$EGD > u_EGD

# Step 3: Determine observations in each quadrant
q1 <- x_sup & y_sup
q2 <- !x_sup & y_sup
q3 <- !x_sup & !y_sup
q4 <- x_sup & !y_sup

# Step 4: Count observations in each quadrant
count_q1 <- sum(q1)
count_q2 <- sum(q2)
count_q3 <- sum(q3)
count_q4 <- sum(q4)

cat("Cuadrante 1:", count_q1, "\n")
cat("Cuadrante 2:", count_q2, "\n")
cat("Cuadrante 3:", count_q3, "\n")
cat("Cuadrante 4:", count_q4, "\n")
```

No se oberva a simple vista un correlación lineal entre los puntos. Aunque parecería existir una correlación positiva ya que se observa mayor cantidad de puntos en los cuadrantes I y III.

### b) Coeficiente correlación muestral

```{r}
#Analizamos normalidad de las variables

hist(g_cerdos$PV, 
     breaks = 10, 
     main = "", 
     xlab = "Peso Vivo (Kg)",
     border = "darkred" ) 

hist(g_cerdos$EGD, 
     breaks = 10, 
     main = "", 
     xlab = "Espesor Grasa Dorsal (mm)",
     border = "blue" )
```

```{r}
qqnorm( g_cerdos$PV,
        main = "Peso Vivo (Kg)", 
        col = "darkred" ) 
qqline( g_cerdos$PV )

qqnorm( g_cerdos$EGD, 
        main = "Espesor Grasa Dorsal (mm)", 
        col = "blue" ) 
qqline( g_cerdos$EGD )
```

Analizo que la distribución conjunta de las variables sea normal bivariada. Si no se cumple, la correlación debe estimarse en forma no paramétrica mediante el coeficiente de correlación de Spearman.

```{r}
result <- mvn(g_cerdos, mvnTest = "hz")
result$multivariateNormality
```

Puede entonces, sostenerse el supuesto distribucional normal bivariado para estas variables.

### c) Supuestos

Dado que se cumplen los supuestos de normalidad, entonces puedo usar el test de correlación de Pearson dado que se cumplen los supuestos de normalidad y linealidad.

```{r}
cor( g_cerdos$PV, g_cerdos$EGD )
cor( g_cerdos$PV, g_cerdos$EGD, method="pearson" )
cor.test( g_cerdos$PV, g_cerdos$EGD, method="pearson" )
```

No rechazas H0 porque el 0 está incluido (el rango va de -0.11 a 0.56). Por lo tanto no existe correlación entre las variables.

## Ejercicio 1.2

### Dataset

```{r}
anscombe <- read_excel("./datasets/anscombe.xlsx") 
```

### a) Diagramas de dispresión

```{r}

#Tengo que hacerlo para cada par de variables

#Creo un df para almacenar las medias para el punto b
df_mean <- data.frame()
df_sd <- data.frame()
df_cor <- data.frame()

for ( i in 1:4 ) {
  df <- data.frame( x = anscombe[,i], y = anscombe[,i+4] )
  names(df) <- c("x","y")

  #Calculo la media de X
  uX <- mean(df$x)
  #Calculo la media de Y
  uY <- mean(df$y)
  #Almaceno las medias
  df_mean <- rbind(df_mean, data.frame(i, uX, uY))
  
  title <- paste0("Anscombe - ", "x",i, " vs ", "y",i)
  subtitle <- paste0("uX: ", uX, " - uY: ", uY)
  #Grafico
  plot <- ggplot( data = df, aes( x = x, y = y) ) +
    geom_point( colour = "red4" ) +
    ggtitle( title, subtitle = subtitle ) +
    theme_bw() + 
    theme( plot.title = element_text( hjust = 0.5 ) ) +
    geom_quadrant_lines(xintercept = uX , yintercept = uY )
  
  print(plot)
  
  #Calculo sd de X
  sdX <- sd(df$x)
  #Calculo sd de Y
  sdY <- sd(df$y)
  #Almaceno los sd
  df_sd <- rbind(df_sd, data.frame(i, sdX, sdY))
  
  #Calculo de correlacion de cada par
  df_cor <- rbind(df_cor, data.frame(i, cor(df$x,df$y)))
  
  #Borro las variables creadas temporalmente
  rm(df,uX,uY, sdX, sdY, i, title, subtitle, plot)
}
```

### b) Valores medios

```{r}
df_mean
```

### c) Valores de la dispresión

```{r}
df_sd
```

### d) Coeficiente muestral de correlación lineal

```{r}
df_cor
```

### e) Observar, comentar y concluir

Los cuartetos de Anscombe se utilizaron para resaltar la importancia de visualizar los datos y no depender únicamente de medidas resumidas. Destacan la idea de que los valores atípicos y las formas de distribución pueden no ser detectados mediante estadísticas descriptivas básicas. Anscombe argumentaba que los estadísticos deben ser cautelosos y considerar siempre la visualización de los datos antes de realizar cualquier análisis o toma de decisiones basada en ellos. Estos cuartetos son un recordatorio de que la exploración gráfica de los datos es esencial para comprender su estructura y evitar sacar conclusiones erróneas basadas únicamente en medidas numéricas.

## Ejercicio 1.3

### Dataset

```{r}
icm <- read_excel("./datasets/peso_edad_colest.xlsx") 
```

### a) Diagramas dispersión

#### Colesterol en función de la edad

```{r}
ggplot( data = icm, aes( x = edad, y = colest ) ) +
  geom_point( colour = "orange", size = 2) +
  ggtitle( "Colesterol en función de la edad" ) +
  theme_bw() + 
  theme( plot.title = element_text( hjust = 0.5 ) ) +
  geom_quadrant_lines(xintercept = mean(icm$edad) , yintercept = mean(icm$colest) )
```

#### Colesteril en función del peso

```{r}
ggplot( data = icm, aes( x = peso, y = colest ) ) +
  geom_point( colour = "purple", size = 2) +
  ggtitle( "Colesterol en función del peso" ) +
  theme_bw() + 
  theme( plot.title = element_text( hjust = 0.5 ) ) +
  geom_quadrant_lines(xintercept = mean(icm$peso) , yintercept = mean(icm$colest) )
```

```{r}
ggplot( data = g_cerdos, aes( x = PV, y = EGD ) ) +
  geom_point( colour = "red4", size = 2) +
  ggtitle( "Peso Vivo (Kg) vs Espesor Grasa Dorsal (mm)" ) +
  theme_bw() + 
  theme( plot.title = element_text( hjust = 0.5 ) ) +
  geom_quadrant_lines(xintercept = u_PV , yintercept = u_EGD )
```

### b) Coefiecientes modelo lineal

```{r}
# Modelo lineal para el colesterol en función de la edad
icm_lm <- lm(colest ~ edad, data = icm)
summary(icm_lm)
```

```{r}
overall_p( icm_lm )
```

### c) Intervalos de confianza

```{r}
intervalos_confianza <- confint(icm_lm)
print(intervalos_confianza)
```

```{r}
#Test de Wald
library(aod)

wald.test(Sigma = vcov(icm_lm), b = coef(icm_lm), Terms = 1)
```

### d) Predicciones

```{r}
nuevos_datos <- data.frame(edad=c(25,48,80))
predicciones <- predict(object = icm_lm,
                        newdata = data.frame(nuevos_datos))
predicciones
```

```{r}
min(icm$colest)
max(icm$colest)
```

```{r}
int_conf <- predict(object = icm_lm,
                    newdata= nuevos_datos,
                    interval = "confidence",
                    level = 0.95)
int_conf
```

Se puede estimar el valor de E(Y) para x = 80 años aunque la predicción dado los datos de función de regresión, la predicción no será confiable ya que no es un valor de colesterol compatible con los valores humanos posibles.

Puedo graficar esos puntos para visualizarlos sobre el gráfico original.

```{r}

icm_2 <- rbind(icm, c(0,25,237.2730))
icm_2 <- rbind(icm_2, c(0,48,367.7024))
icm_2 <- rbind(icm_2, c(0,80,549.1693))

ggplot(data = icm_2,
       mapping = aes(x = edad, y = colest)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs( title = "Colesterol en función de la edad" ) + 
  geom_point(data = nuevos_datos, 
             aes(y = predicciones), 
             color = "blue", size = 2) +
  geom_smooth(method = "lm", 
              se = TRUE, 
              level=0.95, 
              color = "black") + 
  theme_bw() + 
  theme( plot.title = element_text(hjust = 0.5) )

```

### e) Normalidad de residuos

```{r}
#Analizamos si los residuos son normales 
icm2 <- icm
icm2$prediccion <- icm_lm$fitted.values 
icm2$residuos <- icm_lm$residuals

ggplot(data = icm2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", 
                        mid = "grey", 
                        high = "red") + 
  geom_hline(yintercept = 0) + 
  geom_segment(aes(xend = prediccion, 
                   yend = 0), 
                  alpha = 0.2) + 
  labs(title = "Distribución de los residuos", 
       x = "predicción modelo", 
       y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), 
        legend.position = "none")

ggplot(data = icm2, 
       aes(x = residuos)) + 
  geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))

qqnorm(icm_lm$residuals) 
qqline(icm_lm$residuals)

shapiro.test(icm_lm$residuals)
```

Analizamos si los residuos tienen varianza constante.

```{r}
#Test de Breush-Pagan
library(lmtest) 
bptest(icm_lm)
```

Concluimos que no se rechaza homocedasticidad

```{r}
#Test de Durbin-Watson
library(car)
dwt(icm_lm)
```

Es decir que rechaza no autocorrelación en los residuos, es decir hay autocorrelación en los residuos, por lo tanto no se valida el supuesto de independencia de las observaciones.

## Ejercicio 1.4

### Dataset

```{r}
energia <- read_excel("./datasets/energia.xlsx") 
```

### a) Diagrama de dispersión

```{r}

ggplot( data = energia, aes( x = Hora, y = Energía ) ) +
  geom_point( colour = "orange", size = 2) +
  ggtitle( "Energía por hora" ) +
  theme_bw() + 
  theme( plot.title = element_text( hjust = 0.5 ) ) +
  geom_quadrant_lines(xintercept = mean(energia$Hora) , yintercept = mean(energia$Energía) )
```

### b) **Esimar un modelo lineal y verificar la normalidad de los residuos del mismo**

```{r}
modenerg1 <- lm( Energía ~ Hora, data = energia )
summary( modenerg1 )
```

```{r}

overall_p <- function( my_model, nivel_significancia = 0.05 ) {
  
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
  
  #Shapiro Test
  t_sha <- shapiro.test( my_model$residuals )
  t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
                       "Los residuos son normales.",
                       "Los residuos NO son normales.")
  
  #BP Test
  t_bp <- bptest( my_model )
  t_bp_obs <- ifelse( unname(t_bp$p.value) > nivel_significancia,
                     "Homocedasticidad. La varianza de los residuos es constante.",
                     "Heterocedasticidad. La varianza de los residuos NO es constante.")
  
  #Durbin-Watson Test
  t_dwt <- dwt( my_model )
  t_dwt_obs <- ifelse( t_dwt$dw > 1.5 && t_dwt$dw < 2.5,
                      "No hay autocorrelación. Los residuos son independientes.",
                      "Hay autocorrelación. Los residuos NO son independientes.")
  
  resultados <- data.frame(
    Prueba = c("Shapiro", "Breusch-Pagan", "Durbin-Watson"),
    P_Value = c(t_sha$p.value, unname(t_bp$p.value), t_dwt$p)
  )
  
  resultados$Hipotesis <- ifelse( resultados$P_Value > nivel_significancia, "Aceptada", "Rechazada" )
  resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs,
                                     ifelse( resultados$Prueba == "Breusch-Pagan", t_bp_obs, t_dwt_obs ) )

  return(resultados)
}

overall_p(modenerg1)
```

```{r}
r <- dwt(modenerg1)
r$dw
```

### c)

### d)

## Ejercicio 1.5

### Dataset

```{r}
inmo <- read.csv2("./datasets/inmobiliaria.csv", dec = ".") 
```

### a)

### b)

### c)

### d)

### e)

## Ejercicio 1.6

### Dataset

```{r}
estudio <- read.csv2("./datasets/estudio.csv", dec = ".")
```

### a)

```{r}
mod_hs_est <- lm ( puntaje ~ horas_estudio, data = estudio )
summary( mod_hs_est )
```

### b)

```{r}
test_supuestos( mod_hs_est )
```

```{r}
durbinWatsonTest( mod_hs_est )
```

### c)

### d)

### e)
