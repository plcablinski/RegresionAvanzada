---
title: "Recursos para práctica - Regresión Avanzada 1-6"
output: html_document
date: "2024-06-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Recordar que está hecho con IA Generativa, tomar todos los resguardos habituales

## Guía de Resolución de Problemas para Regresión Avanzada en R

Esta guía te ayudará a abordar problemas de regresión de forma estructurada, cubriendo desde la exploración de datos hasta la interpretación y comunicación de resultados. 

**Clase 1: Regresión Lineal Simple**

#### Paso 1: Exploración de Datos

1. **Carga y Visualización de los Datos**:
   - **Código en R**:
```{r}
     data <- read.csv("inmobiliaria.csv", sep=";", header=TRUE)
     head(data)
     summary(data)
     str(data) # Para ver la estructura de los datos
```
   - **Consideraciones**:
     - **Verifica la correcta carga de datos:** Asegúrate de que los datos se hayan cargado correctamente en R. Inspecciona las primeras filas del conjunto de datos con `head(data)` para confirmar que los nombres de las variables y los valores se muestran como se espera.
     - **Inspecciona la estructura, tipos de variables y posibles valores faltantes o anómalos:** Utiliza `summary(data)` para obtener estadísticas descriptivas de cada variable, como la media, mediana, mínimo, máximo y cuartiles. Observa si hay valores inusuales o extremos que puedan indicar errores de entrada de datos o valores atípicos. La función `str(data)` te mostrará la estructura del conjunto de datos, incluyendo el número de observaciones y variables, así como el tipo de cada variable (numérica, factor, etc.).

#### Paso 2: Análisis Exploratorio de Datos (EDA)

2. **Análisis Univariado**:
   - **Código en R**:
```{r}
     library(psych) # Para estadísticas descriptivas
     describe(data) 
     hist(data$variable, breaks = 10, main = "Histograma", xlab = "Variable")
     boxplot(data$variable, main = "Diagrama de Caja", ylab = "Variable")
```
   - **Consideraciones**:
     - **Examina medidas de tendencia central, dispersión y forma para cada variable:** La función `describe(data)` proporciona estadísticas descriptivas detalladas para cada variable, incluyendo la media, mediana, desviación estándar, rango intercuartílico, asimetría y curtosis. Analiza estas medidas para comprender la distribución de cada variable.
     - **Visualiza la distribución de las variables con histogramas y diagramas de caja:** Los histogramas muestran la frecuencia de los valores en diferentes intervalos, lo que te permite visualizar la forma de la distribución. Los diagramas de caja muestran la mediana, los cuartiles y los valores atípicos, lo que te ayuda a identificar la dispersión y la presencia de valores extremos.

3. **Análisis Bivariado**:
   - **Código en R**:
```{r}
     library(ggplot2)
     ggplot(data, aes(x = variable_independiente, y = variable_dependiente)) +
       geom_point() +
       geom_smooth(method = "lm", se = FALSE) + # Línea de tendencia
       labs(title = "Diagrama de Dispersión", x = "Variable Independiente", y = "Variable Dependiente")
     cor(data$variable_independiente, data$variable_dependiente) # Correlación
     cor.test(data$variable_independiente, data$variable_dependiente) # Prueba de correlación
     library(corrplot) # Para correlogramas
     corrplot(cor(data), method = "circle") 
```
   - **Consideraciones**:
     - **Observa la relación entre variables con diagramas de dispersión y líneas de tendencia:** Los diagramas de dispersión muestran la relación entre dos variables, y las líneas de tendencia ayudan a visualizar la dirección y la fuerza de la relación.
     - **Calcula la correlación y realiza pruebas de hipótesis para la correlación:** La función `cor()` calcula el coeficiente de correlación de Pearson, que mide la fuerza y la dirección de la relación lineal entre dos variables. La función `cor.test()` realiza una prueba de hipótesis para determinar si la correlación es significativamente diferente de cero.
     - **Visualiza la matriz de correlación con un correlograma:** Un correlograma es una representación gráfica de la matriz de correlación, que muestra la correlación entre todas las parejas de variables en el conjunto de datos. Esto te ayuda a identificar rápidamente las variables que están altamente correlacionadas.

#### Paso 3: Ajuste del Modelo de Regresión Lineal Simple

4. **Ajuste del Modelo**:
   - **Código en R**:
```{r}
     modelo <- lm(variable_dependiente ~ variable_independiente, data = data)
     summary(modelo)
```
   - **Consideraciones**:
     - **Examina los coeficientes del modelo:** Los coeficientes del modelo representan la intersección (intercept) y la pendiente de la línea de regresión. La intersección es el valor predicho de la variable dependiente cuando la variable independiente es cero, y la pendiente indica cuánto cambia la variable dependiente por cada unidad de cambio en la variable independiente.
     - **Verifica la significancia de los coeficientes utilizando los p-valores:** Los p-valores asociados a los coeficientes indican la probabilidad de obtener los resultados observados si la hipótesis nula (que el coeficiente es igual a cero) fuera cierta. Un p-valor menor a 0.05 generalmente se considera significativo, lo que sugiere que la variable predictora tiene un efecto significativo sobre la variable dependiente.
     - **Interpreta el R-cuadrado y el error estándar de los residuos:** El R-cuadrado (R-squared) mide la proporción de la varianza en la variable dependiente que es explicada por el modelo. Un R-cuadrado más alto indica un mejor ajuste del modelo. El error estándar de los residuos (residual standard error) es una medida de la dispersión de los residuos alrededor de la línea de regresión. Un error estándar más bajo indica un mejor ajuste del modelo.

#### Paso 4: Validación de Supuestos

5. **Análisis de Residuos**:
   - **Código en R**:
```{r}
     par(mfrow = c(2, 2))
     plot(modelo)
     shapiro.test(residuals(modelo)) # Prueba de normalidad
     library(lmtest)
     bptest(modelo) # Prueba de Breusch-Pagan para heterocedasticidad
     library(car)
     durbinWatsonTest(modelo) # Prueba de Durbin-Watson para autocorrelación
```
   - **Gráficos generados**:
     - **Residuals vs Fitted:** Este gráfico muestra los residuos en el eje y y los valores ajustados en el eje x. Se utiliza para evaluar la linealidad y la homocedasticidad.
     - **Normal Q-Q:** Este gráfico compara los cuantiles de los residuos con los cuantiles de una distribución normal. Se utiliza para evaluar la normalidad de los residuos.
     - **Scale-Location:** Este gráfico muestra la raíz cuadrada de los residuos estandarizados en el eje y y los valores ajustados en el eje x. Se utiliza para evaluar la homocedasticidad.
     - **Residuals vs Leverage:** Este gráfico muestra los residuos estandarizados en el eje y y la leverage en el eje x. Se utiliza para identificar puntos influyentes.
   - **Consideraciones**:
     - **Linealidad:** Los residuos deben distribuirse aleatoriamente alrededor de la línea horizontal en el gráfico "Residuals vs Fitted". Si hay un patrón claro en los residuos, como una curva o una forma de embudo, esto sugiere que la relación entre las variables no es lineal.
     - **Homocedasticidad**: Los residuos deben tener una varianza constante a lo largo de los valores ajustados. Si la dispersión de los residuos aumenta o disminuye a medida que aumentan los valores ajustados, esto indica heterocedasticidad.
     - **Normalidad**: Los puntos en el gráfico "Normal Q-Q" deben seguir aproximadamente la línea diagonal. Si los puntos se desvían significativamente de la línea, esto sugiere que los residuos no siguen una distribución normal.
     - **Independencia**: Los residuos deben ser independientes entre sí. La presencia de patrones en el gráfico "Residuals vs Leverage" puede indicar autocorrelación en los residuos.
     - **Puntos influyentes:** Los puntos con alta leverage o alta distancia de Cook en el gráfico "Residuals vs Leverage" pueden ser influyentes, lo que significa que tienen un gran impacto en el ajuste del modelo.
     - **Pruebas estadísticas:** Además de los gráficos de diagnóstico, realiza pruebas estadísticas para confirmar los supuestos. La prueba de Shapiro-Wilk se utiliza para evaluar la normalidad, la prueba de Breusch-Pagan se utiliza para evaluar la homocedasticidad, y la prueba de Durbin-Watson se utiliza para evaluar la autocorrelación.

#### Paso 5: Transformaciones y Corrección de Problemas

6. **Aplicación de Transformaciones**:
   - **Código en R**:
```{r}
     library(MASS)
     boxcox(modelo, lambda = seq(-2, 2, by = 0.1))
```
   - **Consideraciones**:
     - **Transformación Box-Cox:** Si los residuos no son normales o hay heterocedasticidad, la transformación Box-Cox puede ayudar a corregir estos problemas. La función `boxcox()` genera un gráfico que muestra el logaritmo de la verosimilitud del modelo para diferentes valores de lambda. El valor óptimo de lambda es el que maximiza la verosimilitud.
     - **Otras transformaciones:** Si la transformación Box-Cox no es efectiva, considera otras transformaciones como el logaritmo, la raíz cuadrada o la inversa.

7. **Reajuste del Modelo con Transformaciones**:
   - **Código en R**:
```{r}
     modelo_transformado <- lm(log(variable_dependiente) ~ variable_independiente, data = data)
     summary(modelo_transformado)
     plot(modelo_transformado)
```
   - **Consideraciones**:
     - **Reajuste del modelo:** Una vez que hayas aplicado una transformación, reajusta el modelo de regresión lineal simple con la variable transformada.
     - **Verificación de supuestos:** Verifica nuevamente los supuestos del modelo utilizando los gráficos de diagnóstico y las pruebas estadísticas.

#### Paso 6: Imputación de Datos Faltantes (Si es necesario)

8. **Imputación de Datos**:
   - **Código en R**:
```{r}
     library(mice) # Para imputación múltiple
     imputed_data <- mice(data, m = 5, method = "pmm") # Imputación predictiva de la media
     complete_data <- complete(imputed_data, 1) # Completa el conjunto de datos
```
   - **Consideraciones**:
     - **Imputación de datos faltantes:** Si hay datos faltantes en el conjunto de datos, la imputación puede ser una alternativa a la eliminación de los registros incompletos. La imputación múltiple es un método que genera múltiples conjuntos de datos imputados, cada uno con diferentes valores imputados para los datos faltantes.
     - **Métodos de imputación:** Hay varios métodos de imputación disponibles, como la imputación predictiva de la media (pmm), la imputación por regresión y la imputación por vecino más cercano (knn).

#### Paso 7: Interpretación y Comunicación de Resultados

9. **Interpretación de Resultados**:
   - **Consideraciones**:
     - **Interpretación de coeficientes:** Interpreta los coeficientes del modelo final, teniendo en cuenta si se ha aplicado alguna transformación. Si se ha utilizado una transformación, asegúrate de interpretar los coeficientes en términos de la variable original.
     - **Efecto de las transformaciones:** Explica cómo las transformaciones o la imputación han mejorado el ajuste del modelo y la validez de los supuestos. Por ejemplo, si la transformación Box-Cox ha corregido la heterocedasticidad, explica cómo la varianza de los residuos es ahora más constante.
     - **Conclusiones prácticas:** Traduce los resultados técnicos en conclusiones prácticas y recomendaciones para el "cliente" o la situación planteada. Por ejemplo, si el modelo predice el precio de una casa en función de su tamaño, explica cómo el tamaño de la casa afecta el precio y qué recomendaciones se pueden hacer a los compradores o vendedores.

10. **Comunicación de Resultados**:
    - **Consejos**:
      - **Claridad y concisión:** Presenta los resultados de forma clara y concisa, utilizando un lenguaje que sea comprensible para la audiencia.
      - **Visualizaciones:** Usa gráficos para ilustrar la relación entre las variables y el ajuste del modelo. Los diagramas de dispersión, los histogramas y los gráficos de residuos son útiles para comunicar los resultados de la regresión lineal simple.
      - **Interpretación:** Asegúrate de incluir la interpretación de los coeficientes, la significancia de los predictores y las medidas de bondad de ajuste (R-cuadrado, error estándar de los residuos).

**Clase 2: Análisis Diagnóstico y Cuadrados Mínimos Ponderados (WLS)**

* Sigue los pasos 1-5 de la Clase 1 para evaluar los supuestos del modelo.

#### Paso 6: Identificación y Tratamiento de Valores Atípicos e Influyentes

1. **Identificación de Valores Atípicos e Influyentes**:
   - **Código en R**:
```{r}
     library(car)
     influencePlot(modelo) # Gráfico de leverage y distancia de Cook
     outlierTest(modelo) # Prueba de outliers
```
   - **Consideraciones**:
     - **Leverage:** La leverage mide la influencia de una observación individual en el ajuste del modelo. Los puntos con alta leverage tienen valores de x que están lejos del promedio de los valores de x, lo que significa que tienen un mayor potencial para influir en la pendiente de la línea de regresión.
     - **Distancia de Cook:** La distancia de Cook mide el impacto de eliminar una observación individual del modelo. Los puntos con alta distancia de Cook tienen un gran impacto en el ajuste del modelo, lo que sugiere que pueden ser influyentes.
     - **Outliers:** Los outliers son puntos que se encuentran lejos del patrón general de los datos. Pueden ser causados por errores de entrada de datos o por casos genuinos que son diferentes del resto de los datos.
     - **Tratamiento de valores atípicos e influyentes:** Si se identifican valores atípicos o influyentes, investiga la causa de estos puntos. Si son errores de entrada de datos, corrígelos o elimínalos. Si son casos genuinos, considera modelos robustos o transformaciones de variables.

2. **Diagnóstico de Residuos**:
   - **Código en R**:
```{r}
     par(mfrow = c(2, 2))
     plot(modelo)
```
   - **Consideraciones**:
     - **Patrones en los residuos:** Revisa los gráficos de diagnóstico para detectar patrones en los residuos que puedan indicar violaciones de los supuestos del modelo. Por ejemplo, una forma de embudo en el gráfico "Residuals vs Fitted" indica heterocedasticidad.
     - **Puntos influyentes:** Los puntos que se destacan en los gráficos de diagnóstico, como los puntos con alta leverage o alta distancia de Cook, pueden ser influyentes.

#### Paso 7: Aplicación de Cuadrados Mínimos Ponderados (WLS)

1. **Ajuste del Modelo WLS**:
   - **Cálculo de Pesos**:
     - **Código en R**:
```{r}
       pesos <- 1 / lm(abs(residuals(modelo)) ~ fitted(modelo))$fitted.values^2
       modelo_wls <- lm(variable_dependiente ~ variable_independiente, data = datos, weights = pesos)
       summary(modelo_wls)
```
   - **Consideraciones**:
     - **Heterocedasticidad:** La heterocedasticidad ocurre cuando la varianza de los residuos no es constante a lo largo de los valores ajustados.
     - **WLS:** El método de mínimos cuadrados ponderados (WLS) se utiliza para corregir la heterocedasticidad. Asigna pesos a las observaciones, dando más peso a las observaciones con menor varianza y menos peso a las observaciones con mayor varianza.
     - **Cálculo de pesos:** Hay varios métodos para calcular los pesos en WLS. Un método común es utilizar el inverso de la varianza estimada de los residuos para cada valor ajustado.

#### Paso 8: Interpretación y Comunicación de Resultados

* Sigue los pasos 9-10 de la Clase 1 para interpretar y comunicar los resultados.

**Clase 3: Regresión Lineal Múltiple, Selección de Variables y Multicolinealidad**

#### Paso 1: Exploración de Datos

* Sigue los pasos 1-3 de la Clase 1 para explorar los datos.

#### Paso 2: Ajuste del Modelo de Regresión Lineal Múltiple

1. **Ajuste del Modelo**:
   - **Código en R**:
```{r}
     modelo_multiple <- lm(variable_dependiente ~ variable1 + variable2 + variable3, data = data)
     summary(modelo_multiple)
```
   - **Consideraciones**:
     - **Interpretación de coeficientes:** Los coeficientes del modelo representan el cambio en la variable dependiente por cada unidad de cambio en la variable predictora, manteniendo constantes las demás variables predictoras.
     - **Significancia de los coeficientes:** Los p-valores asociados a los coeficientes indican la significancia estadística de cada predictor.
     - **R-cuadrado y R-cuadrado ajustado:** El R-cuadrado mide la proporción de la varianza en la variable dependiente que es explicada por el modelo. El R-cuadrado ajustado penaliza la inclusión de variables predictoras adicionales, lo que lo convierte en una mejor medida de la bondad de ajuste cuando se comparan modelos con diferente número de predictores.
     - **Error estándar de los residuos:** El error estándar de los residuos es una medida de la dispersión de los residuos alrededor del plano de regresión.

#### Paso 3: Validación de Supuestos del Modelo

* Sigue los pasos 5 de la Clase 1 para validar los supuestos del modelo.

#### Paso 4: Selección de Variables

1. **Selección de Variables**:
   - **Método Stepwise**:
     - **Código en R**:
```{r}
       library(MASS)
       modelo_step <- stepAIC(modelo_multiple, direction = "both")
       summary(modelo_step)
```
     - **Consideraciones:** El método stepwise agrega o elimina variables predictoras del modelo de forma iterativa, basándose en un criterio de selección como el AIC (Criterio de Información de Akaike). La dirección "both" indica que el método puede agregar o eliminar variables en cada paso.
   - **Método Forward y Backward**:
     - **Código en R**:
```{r}
       modelo_forward <- stepAIC(modelo_multiple, direction = "forward")
       modelo_backward <- stepAIC(modelo_multiple, direction = "backward")
       summary(modelo_forward)
       summary(modelo_backward)
```
     - **Consideraciones:** El método forward comienza con un modelo sin predictores y agrega variables de forma iterativa, mientras que el método backward comienza con un modelo con todos los predictores y elimina variables de forma iterativa.
   - **Best Subset Selection**:
     - **Código en R**:
```{r}
       library(leaps)
       best_subsets <- regsubsets(variable_dependiente ~ ., data = data, nvmax = 5)
       summary(best_subsets)
       plot(summary(best_subsets)$adjr2, type = "b", xlab = "Número de Predictores", ylab = "R-cuadrado Ajustado")
```
     - **Consideraciones:** El método "best subset selection" evalúa todos los posibles subconjuntos de variables predictoras y selecciona el mejor modelo para cada tamaño de subconjunto, basándose en un criterio de selección como el R-cuadrado ajustado.

#### Paso 5: Diagnóstico y Tratamiento de Multicolinealidad

1. **Detección de Multicolinealidad**:
   - **Cálculo del VIF**:
     - **Código en R**:
```{r}
       library(car)
       vif(modelo_multiple)
```
   - **Interpretación**:
     - **VIF:** El Factor de Inflación de la Varianza (VIF) mide cuánto aumenta la varianza de un coeficiente de regresión debido a la multicolinealidad. Un VIF de 1 indica que no hay multicolinealidad, mientras que valores más altos indican una mayor multicolinealidad.
     - **Umbral de VIF:** Un VIF mayor a 10 generalmente se considera un indicador de multicolinealidad problemática.

2. **Tratamiento de Multicolinealidad**:
   - **Eliminación de variables:** Si dos o más variables predictoras están altamente correlacionadas, considera eliminar una de ellas del modelo.
   - **Combinación de variables:** Si las variables altamente correlacionadas tienen un significado similar, considera combinarlas en una sola variable.
   - **Métodos de regularización:** Los métodos de regularización, como Ridge Regression y Lasso Regression, pueden ayudar a reducir la multicolinealidad al penalizar los coeficientes de regresión grandes.

#### Paso 6: Interpretación y Comunicación de Resultados

* Sigue los pasos 9-10 de la Clase 1 para interpretar y comunicar los resultados.

**Clase 4: Métodos de Regularización y Regresión de Componentes Principales**

#### Paso 1: Exploración de Datos

* Sigue los pasos 1-3 de la Clase 1 para explorar los datos.

#### Paso 2: Métodos de Regularización

1. **Ridge Regression**:
   - **Ajuste del Modelo**:
     - **Código en R**:
```{r}
       library(glmnet)
       x <- model.matrix(variable_dependiente ~ ., data = data)[, -1]
       y <- data$variable_dependiente
       cv_ridge <- cv.glmnet(x, y, alpha = 0)
       plot(cv_ridge)
       best_lambda_ridge <- cv_ridge$lambda.min
       modelo_ridge <- glmnet(x, y, alpha = 0, lambda = best_lambda_ridge)
       coef(modelo_ridge)
```
   - **Interpretación**:
     - **Lambda:** El parámetro lambda controla la cantidad de penalización aplicada a los coeficientes de regresión. Un lambda más alto resulta en una mayor penalización y coeficientes más pequeños.
     - **Validación cruzada:** La validación cruzada se utiliza para seleccionar el valor óptimo de lambda que minimiza el error de predicción.
     - **Interpretación de coeficientes:** Los coeficientes del modelo Ridge son más pequeños que los coeficientes del modelo OLS, lo que reduce la varianza del modelo y lo hace menos susceptible a la multicolinealidad.

2. **Lasso Regression**:
   - **Ajuste del Modelo**:
     - **Código en R**:
```{r}
       cv_lasso <- cv.glmnet(x, y, alpha = 1)
       plot(cv_lasso)
       best_lambda_lasso <- cv_lasso$lambda.min
       modelo_lasso <- glmnet(x, y, alpha = 1, lambda = best_lambda_lasso)
       coef(modelo_lasso)
```
   - **Interpretación**:
     - **Selección de variables:** Lasso Regression puede reducir a cero algunos coeficientes de regresión, lo que efectivamente elimina las variables predictoras correspondientes del modelo. Esto hace que Lasso sea útil para la selección de variables.

3. **Elastic Net**:
   - **Ajuste del Modelo**:
     - **Código en R**:
```{r}
       cv_elastic_net <- cv.glmnet(x, y, alpha = 0.5) # Ajusta alfa según sea necesario
       plot(cv_elastic_net)
       best_lambda_enet <- cv_elastic_net$lambda.min
       modelo_enet <- glmnet(x, y, alpha = 0.5, lambda = best_lambda_enet)
       coef(modelo_enet)
```
   - **Interpretación**:
     - **Combinación de penalizaciones:** Elastic Net combina las penalizaciones de Ridge Regression y Lasso Regression. El parámetro alfa controla la mezcla de penalizaciones, donde alfa = 0 corresponde a Ridge Regression y alfa = 1 corresponde a Lasso Regression.

#### Paso 3: Regresión de Componentes Principales (PCR)

1. **Ajuste del Modelo PCR**:
   - **Código en R**:
```{r}
     library(pls)
     pcr_model <- pcr(variable_dependiente ~ ., data = data, scale = TRUE, validation = "CV")
     summary(pcr_model)
     validationplot(pcr_model, val.type = "RMSEP")
     best_ncomp_pcr <- which.min(pcr_model$validation$PRESS)
```
   - **Interpretación**:
     - **Componentes principales:** PCR utiliza las componentes principales de las variables predictoras como nuevas variables predictoras en el modelo de regresión. Las componentes principales son combinaciones lineales de las variables originales que capturan la mayor parte de la varianza en los datos.
     - **Selección del número de componentes:** El número óptimo de componentes principales se selecciona basándose en el error de validación cruzada (RMSEP).
     - **Interpretación de componentes:** Examina los loadings de las componentes principales para entender cómo se relacionan con las variables originales.

#### Paso 4: Regresión Parcial por Mínimos Cuadrados (PLS)

1. **Ajuste del Modelo PLS**:
   - **Código en R**:
```{r}
     plsr_model <- plsr(variable_dependiente ~ ., data = data, scale = TRUE, validation = "CV")
     summary(plsr_model)
     validationplot(plsr_model, val.type = "RMSEP")
     best_ncomp_pls <- which.min(plsr_model$validation$PRESS)
```
   - **Interpretación**:
     - **PLS vs. PCR:** PLS es similar a PCR, pero también tiene en cuenta la variable dependiente al construir las componentes. Esto puede resultar en un modelo más predictivo que PCR.

#### Paso 5: Comparación de Modelos

1. **Comparación de RMSE entre Modelos**:
   - **Código en R**:
```{r}
     # Calcula el RMSE para cada modelo utilizando los datos de prueba
     rmse_ols <- sqrt(mean((predict(modelo_multiple, newdata = test_data) - test_data$variable_dependiente)^2))
     rmse_ridge <- sqrt(mean((predict(modelo_ridge, newx = x_test, s = best_lambda_ridge) - y_test)^2))
     rmse_lasso <- sqrt(mean((predict(modelo_lasso, newx = x_test, s = best_lambda_lasso) - y_test)^2))
     rmse_enet <- sqrt(mean((predict(modelo_enet, newx = x_test, s = best_lambda_enet) - y_test)^2))
     rmse_pcr <- sqrt(mean((predict(pcr_model, newdata = test_data, ncomp = best_ncomp_pcr) - test_data$variable_dependiente)^2))
     rmse_pls <- sqrt(mean((predict(plsr_model, newdata = test_data, ncomp = best_ncomp_pls) - test_data$variable_dependiente)^2))

     # Crea un dataframe con los resultados
     resultados <- data.frame(
       Modelo = c("OLS", "Ridge", "Lasso", "Elastic Net", "PCR", "PLS"),
       RMSE = c(rmse_ols, rmse_ridge, rmse_lasso, rmse_enet, rmse_pcr, rmse_pls)
     )

     # Imprime los resultados
     print(resultados)
```
   - **Consideraciones**:
     - **RMSE:** El Error Cuadrático Medio de la Raíz (RMSE) es una medida común del error de predicción. Un RMSE más bajo indica un mejor ajuste del modelo.
     - **Comparación de modelos:** Compara los RMSE de los diferentes modelos para determinar cuál proporciona las predicciones más precisas.

#### Paso 6: Interpretación y Comunicación de Resultados

* Sigue los pasos 9-10 de la Clase 1 para interpretar y comunicar los resultados.

**Clase 5: ANOVA, Transformaciones Box-Cox, Pruebas No Paramétricas, ANOVA de Dos Vías, Regresión de Cuantiles y Modelos GAM**

#### Paso 1: ANOVA

1. **Ajuste del Modelo ANOVA**:
   - **Código en R**:
```{r}
     aov_model <- aov(variable_dependiente ~ factor1 + factor2, data = datos)
     summary(aov_model)
```
   - **Interpretación**:
     - **P-valores:** Los p-valores asociados a cada factor indican si hay diferencias significativas entre las medias de los grupos para ese factor.
     - **Sum of Squares (Sum Sq):** La suma de cuadrados mide la variación total en la variable dependiente que es explicada por cada factor.
     - **Mean Squares (Mean Sq):** Los cuadrados medios son la suma de cuadrados dividida por los grados de libertad. Se utilizan para calcular el estadístico F.
     - **Estadístico F:** El estadístico F se utiliza para probar la hipótesis nula de que no hay diferencias entre las medias de los grupos.

2. **Gráfico de Medias**:
   - **Código en R**:
```{r}
     library(ggplot2)
     ggplot(datos, aes(x = factor1, y = variable_dependiente, fill = factor2)) +
       geom_bar(stat = "identity", position = "dodge") +
       labs(title = "Medias de los Factores", x = "Factor 1", y = "Variable Dependiente")
```
   - **Consideraciones**:
     - **Visualización de medias:** El gráfico de medias muestra las medias de la variable dependiente para cada combinación de niveles de los factores. Esto ayuda a visualizar los efectos principales y las interacciones entre los factores.

#### Paso 2: Transformaciones Box-Cox

* Sigue los pasos 3-4 de la Clase 5 para aplicar la transformación Box-Cox.

#### Paso 3: Pruebas No Paramétricas

1. **Prueba de Kruskal-Wallis**:
   - **Código en R**:
```{r}
     kruskal.test(variable_dependiente ~ factor1, data = datos)
```
   - **Consideraciones**:
     - **Supuestos de ANOVA:** La prueba de Kruskal-Wallis es una alternativa no paramétrica a ANOVA que no requiere que los datos sigan una distribución normal o que tengan varianzas iguales.
     - **Comparación de medianas:** La prueba de Kruskal-Wallis compara las medianas de los grupos en lugar de las medias.

2. **Prueba de Mann-Whitney**:
   - **Código en R**:
```{r}
     wilcox.test(variable_dependiente ~ factor1, data = datos)
```
   - **Consideraciones**:
     - **Dos grupos:** La prueba de Mann-Whitney es una alternativa no paramétrica al t-test que se utiliza para comparar las medianas de dos grupos.

#### Paso 4: ANOVA de Dos Vías

1. **Ajuste del Modelo ANOVA de Dos Vías**:
   - **Código en R**:
```{r}
     aov2_model <- aov(variable_dependiente ~ factor1 * factor2, data = datos)
     summary(aov2_model)
```
   - **Consideraciones**:
     - **Efectos principales e interacción:** El modelo ANOVA de dos vías evalúa los efectos principales de cada factor y la interacción entre los factores.
     - **Interpretación de p-valores:** Los p-valores asociados a cada factor y a la interacción indican si hay diferencias significativas entre las medias de los grupos.

2. **Gráfico de Interacción**:
   - **Código en R**:
```{r}
     interaction.plot(datos$factor1, datos$factor2, datos$variable_dependiente)
```
   - **Consideraciones**:
     - **Visualización de la interacción:** El gráfico de interacción muestra las medias de la variable dependiente para cada combinación de niveles de los factores. Si las líneas en el gráfico no son paralelas, esto sugiere que hay una interacción entre los factores.

#### Paso 5: Regresión de Cuantiles

1. **Ajuste del Modelo de Regresión de Cuantiles**:
   - **Código en R**:
```{r}
     library(quantreg)
     rq_model <- rq(variable_dependiente ~ variable1 + variable2, tau = 0.5, data = datos)
     summary(rq_model)
```
   - **Consideraciones**:
     - **Cuantiles:** La regresión de cuantiles estima la relación entre las variables predictoras y diferentes cuantiles de la variable dependiente.
     - **Tau:** El parámetro tau especifica el cuantil que se está estimando. Por ejemplo, tau = 0.5 estima la mediana.

2. **Gráfico de Regresión de Cuantiles**:
    - **Código en R**:
```{r}
      plot(rq_model)
```
    - **Consideraciones**:
      - **Visualización de coeficientes:** El gráfico de regresión de cuantiles muestra los coeficientes de regresión para diferentes cuantiles. Esto ayuda a visualizar cómo cambia la relación entre las variables predictoras y la variable dependiente a lo largo de la distribución de la variable dependiente.

#### Paso 6: Modelos GAM (Generalized Additive Models)

1. **Ajuste del Modelo GAM**:
    - **Código en R**:
```{r}
      library(mgcv)
      gam_model <- gam(variable_dependiente ~ s(variable1) + s(variable2), data = datos)
      summary(gam_model)
```
    - **Consideraciones**:
      - **Relaciones no lineales:** Los modelos GAM permiten modelar relaciones no lineales entre las variables predictoras y la variable dependiente.
      - **Funciones suavizadas:** Las funciones suavizadas (smooth functions) se utilizan para capturar las relaciones no lineales.

2. **Gráficos de las Funciones Suavizadas**:
    - **Código en R**:
```{r}
      plot(gam_model, pages = 1)
```
    - **Consideraciones**:
      - **Visualización de relaciones no lineales:** Los gráficos de las funciones suavizadas muestran la relación no lineal entre cada variable predictora y la variable dependiente.

#### Paso 7: Modelos GAMLSS (Generalized Additive Models for Location, Scale and Shape)

1. **Ajuste del Modelo GAMLSS**:
    - **Código en R**:
```{r}
      library(gamlss)
      gamlss_model <- gamlss(variable_dependiente ~ pb(variable1) + pb(variable2), 
                             sigma.formula = ~ pb(variable1) + pb(variable2), 
                             family = NO, data = datos)
      summary(gamlss_model)
```
    - **Consideraciones**:
      - **Modelado de la media y la varianza:** Los modelos GAMLSS permiten modelar la media y la varianza de la variable dependiente en función de las variables predictoras.
      - **Funciones de enlace:** Las funciones de enlace se utilizan para transformar la media y la varianza.

2. **Gráficos de Efectos**:
    - **Código en R**:
```{r}
      term.plot(gamlss_model, pages = 1) # Para mu
      term.plot(gamlss_model, parameter = "sigma", pages = 1) # Para sigma
```
    - **Consideraciones**:
      - **Visualización de relaciones no lineales:** Los gráficos de efectos muestran la relación no lineal entre cada variable predictora y la media y la varianza de la variable dependiente.

#### Paso 8: Interpretación y Comunicación de Resultados

* Sigue los pasos 13-14 de la Clase 5 para interpretar y comunicar los resultados.

### Clase 6: Regresión Logística, Estimación y Modelado, Evaluación del Modelo y Curvas ROC

#### Paso 1: Exploración de Datos

* Sigue los pasos 1-3 de la Clase 1 para explorar los datos, prestando especial atención a la variable dependiente, que debe ser binaria (0/1).

#### Paso 2: Ajuste del Modelo de Regresión Logística

1. **Transformación de Variables Categóricas**:
   - **Código en R**:
```{r}
     data$variable_categorica <- factor(data$variable_categorica)
```
   - **Consideraciones**:
     - **Codificación de variables categóricas:** Asegúrate de que las variables categóricas estén correctamente codificadas como factores en R. Esto permitirá que el modelo de regresión logística las trate como variables categóricas en lugar de numéricas.

2. **Ajuste del Modelo**:
   - **Código en R**:
```{r}
     modelo_logistico <- glm(variable_dependiente ~ variable1 + variable2, family = binomial, data = data)
     summary(modelo_logistico)
```
   - **Interpretación**:
     - **Coeficientes:** Los coeficientes del modelo logístico representan el cambio en el logit (logaritmo de las odds) de la variable dependiente por cada unidad de cambio en la variable predictora, manteniendo constantes las demás variables predictoras.
     - **Significancia de los coeficientes:** Los p-valores asociados a los coeficientes indican la significancia estadística de cada predictor. Un p-valor menor a 0.05 generalmente se considera significativo.
     - **AIC (Criterio de Información de Akaike):** El AIC es una medida de la bondad de ajuste del modelo que penaliza la inclusión de variables predictoras adicionales. Un AIC más bajo indica un mejor ajuste del modelo.
     - **Deviance:** La deviance es una medida de la discrepancia entre el modelo ajustado y los datos observados. Una deviance más baja indica un mejor ajuste del modelo.

#### Paso 3: Evaluación del Modelo

1. **Prueba de Hosmer-Lemeshow**:
   - **Código en R**:
```{r}
     library(ResourceSelection)
     hoslem.test(data$variable_dependiente, fitted(modelo_logistico))
```
   - **Consideraciones**:
     - **Bondad de ajuste:** La prueba de Hosmer-Lemeshow evalúa la bondad de ajuste del modelo de regresión logística. La hipótesis nula es que el modelo se ajusta bien a los datos.
     - **Interpretación del p-valor:** Un p-valor alto (generalmente mayor a 0.05) indica que no hay evidencia para rechazar la hipótesis nula, lo que sugiere que el modelo tiene un buen ajuste.

2. **Matriz de Confusión**:
   - **Código en R**:
```{r}
     library(caret)
     predicciones <- predict(modelo_logistico, type = "response")
     predicciones_clase <- ifelse(predicciones > 0.5, 1, 0) # Ajusta el punto de corte según sea necesario
     confusionMatrix(factor(predicciones_clase), factor(data$variable_dependiente))
```
   - **Consideraciones**:
     - **Clasificación:** La matriz de confusión muestra el número de verdaderos positivos (TP), falsos positivos (FP), verdaderos negativos (TN) y falsos negativos (FN) del modelo.
     - **Exactitud (Accuracy):** La exactitud es la proporción de predicciones correctas del modelo.
     - **Sensibilidad (Sensitivity) o Recall:** La sensibilidad es la proporción de casos positivos que son correctamente identificados por el modelo.
     - **Especificidad (Specificity):** La especificidad es la proporción de casos negativos que son correctamente identificados por el modelo.

3. **Métricas de Evaluación Adicionales**:
   - **Código en R**:
```{r}
     library(caret)
     precision <- posPredValue(factor(predicciones_clase), factor(data$variable_dependiente))
     recall <- sensitivity(factor(predicciones_clase), factor(data$variable_dependiente))
     f1_score <- (2 * precision * recall) / (precision + recall)
     print(paste("Precisión:", precision))
     print(paste("Recall:", recall))
     print(paste("Puntuación F1:", f1_score))
```
   - **Consideraciones**:
     - **Precisión (Precision):** La precisión es la proporción de predicciones positivas que son correctas.
     - **Recall:** El recall es la proporción de casos positivos que son correctamente identificados por el modelo.
     - **Puntuación F1 (F1 Score):** La puntuación F1 es una medida que combina la precisión y el recall. Es la media armónica de la precisión y el recall.

#### Paso 4: Curvas ROC y AUC

1. **Curvas ROC y AUC**:
   - **Generación de la Curva ROC**:
     - **Código en R**:
```{r}
       library(pROC)
       roc_curve <- roc(data$variable_dependiente, predicciones)
       plot(roc_curve)
       auc(roc_curve)
       ci.auc(roc_curve) # Intervalo de confianza para el AUC
```
   - **Consideraciones**:
     - **Curva ROC (Receiver Operating Characteristic):** La curva ROC muestra la relación entre la tasa de verdaderos positivos (sensibilidad) y la tasa de falsos positivos (1 - especificidad) para diferentes puntos de corte.
     - **AUC (Área Bajo la Curva):** El AUC es una medida del rendimiento general del modelo. Un AUC de 0.5 indica que el modelo no es mejor que el azar, mientras que un AUC de 1 indica un modelo perfecto.

#### Paso 5: Regresión Logística con Varias Variables

1. **Interacción entre Variables**:
   - **Código en R**:
```{r}
     modelo_interaccion <- glm(variable_dependiente ~ variable1 * variable2, family = binomial, data = data)
     summary(modelo_interaccion)
```
   - **Consideraciones**:
     - **Interacción:** La interacción entre dos variables predictoras ocurre cuando el efecto de una variable predictora sobre la variable dependiente depende del valor de la otra variable predictora.
     - **Interpretación de coeficientes de interacción:** Los coeficientes de interacción indican el cambio en el logit de la variable dependiente por cada unidad de cambio en la interacción de las variables predictoras.

2. **Selección de Variables**:
   - **Código en R**:
```{r}
     modelo_step <- stepAIC(modelo_logistico, direction = "both")
     summary(modelo_step)
```
   - **Consideraciones**:
     - **Stepwise:** El método stepwise agrega o elimina variables predictoras del modelo de forma iterativa, basándose en un criterio de selección como el AIC.

#### Paso 6: Interpretación de Odds Ratios

1. **Cálculo de Odds Ratios**:
   - **Código en R**:
```{r}
     exp(coef(modelo_logistico)) # Odds ratios
     exp(confint(modelo_logistico)) # Intervalos de confianza para los odds ratios
```
   - **Consideraciones**:
     - **Odds ratios:** Los odds ratios (OR) indican cuánto cambia la probabilidad del resultado por cada unidad de cambio en la variable predictora, manteniendo constantes las demás variables predictoras. Un OR de 1 indica que no hay asociación entre la variable predictora y el resultado, mientras que un OR mayor a 1 indica una asociación positiva y un OR menor a 1 indica una asociación negativa.

#### Paso 7: Calibración del Modelo (Si es necesario)

1. **Calibración del Modelo**:
   - **Código en R**:
```{r}
     library(rms)
     calibrated_model <- calibrate(modelo_logistico, method = "boot", B = 1000)
     plot(calibrated_model)
```
   - **Consideraciones**:
     - **Calibración:** La calibración del modelo ajusta las probabilidades predichas para que se ajusten mejor a las probabilidades observadas. Esto es especialmente importante si se van a utilizar las probabilidades predichas para tomar decisiones.

#### Paso 8: Interpretación y Comunicación de Resultados

1. **Interpretación de Resultados**:
   - **Consideraciones**:
     - **Interpretación de coeficientes:** Interpreta los coeficientes del modelo final, incluyendo los coeficientes de interacción si los hay. Explica cómo las variables predictoras afectan la probabilidad del resultado.
     - **Interpretación de odds ratios:** Interpreta los odds ratios y sus intervalos de confianza.
     - **Evaluación del modelo:** Explica cómo las diferentes métricas de evaluación (exactitud, sensibilidad, especificidad, precisión, recall, puntuación F1, AUC) indican el rendimiento del modelo.
     - **Calibración:** Si se ha realizado la calibración del modelo, explica cómo ha mejorado la precisión de las probabilidades predichas.

2. **Comunicación de Resultados**:
    - **Consejos**:
      - **Claridad y concisión:** Presenta los resultados de forma clara y concisa, utilizando un lenguaje que sea comprensible para la audiencia.
      - **Visualizaciones:** Usa gráficos para ilustrar la curva ROC, la matriz de confusión y los efectos de las variables.
      - **Interpretación:** Asegúrate de incluir la interpretación de los coeficientes, los odds ratios, la significancia de los predictores y las métricas de evaluación del modelo.

**Consideraciones Éticas**

* **Sesgo en los Datos:** Asegúrate de que los datos no reflejen sesgos que puedan llevar a discriminación. Por ejemplo, si el modelo se utiliza para predecir la probabilidad de que un solicitante de préstamo incumpla, asegúrate de que los datos no estén sesgados en contra de ciertos grupos demográficos.
* **Discriminación Algorítmica:** Evalúa si el modelo puede discriminar a ciertos grupos. Por ejemplo, si el modelo se utiliza para predecir la probabilidad de que un candidato sea contratado, asegúrate de que el modelo no esté sesgado en contra de ciertos grupos étnicos o de género.
* **Responsabilidad:** Ten en cuenta las implicaciones éticas de las decisiones basadas en el modelo. Por ejemplo, si el modelo se utiliza para predecir la probabilidad de que un paciente tenga una enfermedad, asegúrate de que el modelo sea preciso y que las decisiones basadas en el modelo se tomen de forma responsable.

**Recuerda:** Esta guía es un punto de partida. Adapta los pasos y las técnicas a tu problema específico y consulta la documentación de R para obtener más información sobre las funciones y los paquetes utilizados. 
