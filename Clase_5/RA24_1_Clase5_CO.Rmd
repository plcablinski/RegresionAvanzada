---
title: "Modelo Lineal Multivariado - Clase 5"
author: "Cecilia Oliva"
date: "04/06/2024"
output:
   html_document:
     toc: yes
     code_folding: show
     toc_float: yes
     df_print: paged
     theme: united
     code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>
<br>

# Modelo lineal mulivariado

<br>

## <span style="color:darkred">Modelo aditivo</span>

<br>

### Ejemplo de datos de glucosa en pacientes

<br>

La descripción de las variables es:

glucosa: valor de glucosa en sangre,

ejercicio: 1 si el paciente hace ejercicio, 0 si no hace,

bmi: indice de masa corporal (body mass index),

peso.evo: la evolución del peso del paciente en el último año. Es una variable categórica que representa: disminución de peso en el último año de 7% o más (1), sin cambio de peso en el último año, menos de 7% de diferencia (2), aumento de peso en el último año de 7% o más (3).

```{r, echo=TRUE}
azucar <- read.table(file = "azucar.txt", header = TRUE)
head(azucar)

names(azucar)
dim(azucar)

Ievo<-factor(azucar$peso.evo) #convierte a la variable en factor
contrasts(Ievo) #da la codificación
```
<br>

Probamos un modelo lineal univariado. Cuando la covariable es binaria no hace falta agregarla al modelo como factor.

```{r, echo=TRUE}
ajuste1<-lm(glucosa ~ ejercicio, data = azucar)
summary(ajuste1)
```
<br>

Consideramos ahora además la variable numérica del índice de masa corporal. Observamos que aumenta el coeficiente de determinación $R^2$.

```{r, echo=TRUE}
ajuste2<-lm(glucosa ~ ejercicio + bmi, data = azucar)
summary(ajuste2)
```
<br>


Probamos usando sólo la variable categórica de evolución del peso. Notar la diferencia en el coeficiente de determinación $R^2$.

```{r, echo=TRUE}
ajuste3<-lm(glucosa ~ Ievo,data=azucar)
summary(ajuste3)

```
<br>

Incluimos al modelo anterior los valores del índice de masa corporal. Se observa aumento del coeficiente de determinación.

```{r, echo=TRUE}
ajuste4<-lm(glucosa ~ Ievo + bmi,data=azucar)
summary(ajuste4)
```
<br>

Comparamos ambos modelos usando el comando anova.

```{r, echo=TRUE}
uno<-lm(glucosa ~ Ievo, data=azucar)
dos<-lm(glucosa ~ Ievo + bmi,data=azucar)
anova(uno,dos)
```
<br>

Se concluye que es significativamente mejor el modelo agregando la variable bmi.

<br>

## <span style="color:darkred">Modelo con interacción</span>

<br>

### Ejemplo de datos de pulso

<br>

Consideremos datos sobre la frecuencia cardíaca o pulso medido a
40 personas antes y después de ejercitar. Se les pidió que registraran su pulso, luego
que corrieran una milla, y luego volvieran a registrar su pulso. Además se registró
su sexo, edad y si eran o no fumadores.

Y = pulso luego de correr una milla (Pulso2)

$X_1$ = pulso en reposo (Pulso1)

$X_2$ =
   1 si la persona es mujer, 
   0 en caso contrario
   
$X_3$ =
   1 si la persona fuma, 
   0 en caso contrario
   
$X_4$ = edad

Interesa explicar el pulso post-ejercicio, en función de algunas de las demás covariables.
Es de interés saber si la edad, o el hábito de fumar inciden en él. La
frecuencia cardíaca es el número de contracciones del corazón o pulsaciones por
unidad de tiempo. Su medida se realiza en unas condiciones determinadas (reposo
o actividad) y se expresa en latidos por minuto.
Tanto el sexo como la condición de fumador son variables dummies o binarias. Las restantes son variables continuas.

```{r, echo=TRUE}
pulso<-read.table(file = "pulso.txt", header = TRUE)
head(pulso)

dim(pulso)#40  5
```

<br>

Modelo aditivo con variables continua y categórica

```{r, echo=TRUE}
ajuste1<-lm(Pulso2~ Pulso1+mujer,data=pulso)
summary(ajuste1)

```

<br>

Modelo con interacción entre variables continua y categórica

```{r, echo=TRUE}

ajuste2<-lm(Pulso2~ Pulso1 * mujer,data=pulso)
summary(ajuste2)

```
<br>

Modelo aditivo con variables cualitativas

```{r, echo=TRUE}
ajusteA<-lm(Pulso2 ~ mujer + fuma, data=pulso)
summary(ajusteA)

```
<br>

Modelo con interaccion entre variables cualitativas

```{r, echo=TRUE}
ajusteB<-lm(Pulso2 ~ mujer * fuma, data=pulso)
summary(ajusteB)


```
<br>


### Ejemplo de datos de drogas

<br>

Las dos primeras columnas representan cantidades de droga consumida, la tercera representa la variable continua de niveles de una sustancia en sangre.

```{r, echo=TRUE}

droga<-read.table("ejemploint.txt",header=TRUE)
head(droga)

dim(droga)
```
<br>

Modelo con interacción entre variables cuantitativas

```{r, echo=TRUE}

ajustedroga<-lm(YY~ drogaA * drogaB,data=droga)
summary(ajustedroga)

```
<br>

Si en el ajuste presentado la interacción hubiera resultado significativa y el efecto de la droga A no hubiera resultado significativo, de todos modos, debe conservarse la droga A como covariable en el modelo, puesto que se conservará la interacción.




<br>


# ANOVA y test de Kruskal Wallis

## <span style="color:darkred">ANOVA de 1 factor</span>

Se desea analizar los datos de un experimento para estudiar el efecto del porcentaje de algodón sobre la resistencia a la tensión de una fibra sintética.

```{r echo=TRUE}
porcentaje<-c(rep(15,5),rep(20,5),rep(25,5),rep(30,5),rep(35,5))
resistencia<-c(7,7,15,11,9,12,17,12,18,18,14,18,18,19,19,19,25,22,19,23,7,10,11,15,11)
porcAlgodon <-data.frame(porcentaje,resistencia)

porcentaje.f=factor(porcentaje)

plot(resistencia~porcentaje.f)# idem boxplot(resistencia~porcentaje.f)

AOVporcAlgo<- aov(resistencia~porcentaje.f)
summary(AOVporcAlgo)#idem usando anova(AOVporcAlgo)
```

Aplicando ANOVA el p-valor=9.13e-06 es <0.05, por lo tanto, si se verifican los supuestos de normalidad y homogeneidad de la varianza será válido decir que se rechaza que las medias de cada grupo son todas iguales entre sí, es decir, hay al menos un par que difieren, por lo tanto los porcentajes de algodón influyen sobre la resistencia.

Veamos si se cumplen los supuestos necesarios para aplicar ANOVA.

<br>
<h4>Analizamos igualdad de varianzas:</h4>

```{r echo=TRUE}
library(car)
bartlett.test(resistencia,porcentaje.f)

leveneTest(resistencia~porcentaje.f)
```
<br>

<h4>Analizamos normalidad:</h4>

```{r echo=TRUE}
shapiro.test(residuals(AOVporcAlgo))

library(nortest)
ad.test(residuals(AOVporcAlgo))

library(moments)
agostino.test(residuals(AOVporcAlgo))
```

```{r echo=TRUE}
qqPlot(residuals(AOVporcAlgo),ylab = "residuos", col = "coral",pch = 19, col.lines = "cadetblue",id=FALSE)
```
<br>

Los intervalos de confianza simultáneos para las diferencias de medias 
de Tukey resultan:

```{r echo=TRUE}
TukeyHSD(AOVporcAlgo,conf.level=0.95)
```
<br>

¿Qué conclusión obtenemos?

<br>

<br>

## <span style="color:darkred">ANOVA de 1 factor utilizando transformaciones de Box-Cox</span>

<br>
```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(ggplot2)
library(stats)
library(reshape2)
library(car)
library(nortest)
library(MASS)
#options(repos = c(CRAN = "http://cran.rstudio.com"))
#install.packages("pgirmess")
library(pgirmess)
```

<br>

Con la intención de evaluar la eficacia de un medicamento en el nivel de alerta de unos pacientes, tres dosis (a, b, c) de un determinado fármaco se administraron a 18 sujetos. Se pide analizar la eficacia del medicamento.


```{r echo=TRUE}
dosis<-c(rep("a",6),rep("b",8),rep("c",4))
alerta<-c(30,38,35,41,27,24,32,26,31,29,27,35,21,25,17,21,20,19)
data<-data.frame(dosis,alerta)
head(data,8)
```

Para analizar la eficacia del medicamento, veamos si existen diferencias entre las medias de las tres dosis. Aplicamos ANOVA.

```{r echo=TRUE}
aov.data<-aov(alerta~dosis,data=data)
summary(aov.data)
```

Se puede ver que existen diferencias estadísticamente significativas entre los niveles del fármaco (p=0.00298 <0.05). Para asegurar la validez de esta afirmación realizamos las siguientes pruebas diagnósticas.

La siguiente tabla muestra las medias total y por nivel de los 3 
medicamentos:

```{r echo=TRUE}
print(model.tables(aov.data,"means"))
```


<br>
<h4>Analizamos normalidad:</h4>

```{r echo=TRUE}
qqnorm(resid(aov.data))
qqline(resid(aov.data))

shapiro.test(residuals(aov.data))

ad.test(residuals(aov.data))
```

<br>
<h4>Analizamos igualdad de varianzas (homoscedasticidad):</h4>


```{r echo=TRUE}
boxplot(split(data$alerta,data$dosis),ylab="Alerta",xlab="Dosis")
```

Las varianzas estimadas en cada grupo son:

```{r echo=TRUE}
tapply(data$alerta,data$dosis,var,na.rm=TRUE)

bartlett.test(alerta,dosis)

leveneTest(alerta~as.factor(dosis))

```

OJO: Hay que tener en cuenta el tamaño muestral, cuando el tamaño 
de la muestra es pequeño, incluso grandes desviaciones de la normal 
no se detectan, y cuando el tamaño de la muestra es grande, incluso 
la más mínima desviación de la normalidad logra rechazar la hipótesis
nula. En este caso, al ser la muestra pequeña y el test de Bartlett 
sensible a las desviaciones de la normalidad, este test no detecta 
diferencia de varianzas (heterocedasticidad) en los niveles del factor
(dosis). Por eso, es conveniente utilizar el test de Levene, el cual 
rechaza la homoscedasticidad, lo que indica que NO se cumple uno de los
supuestos del ANOVA.


Para resolver este problema, puede ser útil alguna transformación de 
Box-Cox:

```{r echo=TRUE}
#library(MASS)
boxcox(alerta~dosis,data=data,plotit=TRUE)# el máximo se alcanza en lambda -1.
#bc<-boxcox(alerta~dosis,data=data,plotit=FALSE)# el máximo se alcanza
#bc$x[bc$y==max(bc$y)]#-1
```

Se repite el procedimiento para la variable transformada, y se revisa 
el cumplimiento de supuestos para aplicar ANOVA.

```{r echo=TRUE}
aov.data2=aov(alerta^(-1)~dosis,data=data)
summary(aov.data2)
```

Se obtiene, como con la variable original, diferencias estadísticamente significativas entre los niveles del factor dosis.

<br>
<h4>Revisión de supuestos necesarios para aplicar ANOVA:</h4>

```{r echo=TRUE}
qqnorm(resid(aov.data2))
qqline(resid(aov.data2))

shapiro.test(residuals(aov.data2))

ad.test(residuals(aov.data2))
```

```{r echo=TRUE}
leveneTest(alerta^(-1)~as.factor(dosis),data=data)
```

Con la transformación de Box-Cox realizada se verifican los supuestos
necesarios y por lo tanto el resultado del ANOVA aplicado es válido.

Los intervalos de confianza simultáneos para las diferencias de medias 
de Tukey resultan:

```{r echo=TRUE}
TukeyHSD(aov.data2,conf.level=0.95)
```

<br>


## <span style="color:darkred">Test no paramétrico de Kruskal Wallis</span>
<br>

Un estudio compara el número de huevos que pone un determinado insecto bajo 3 condiciones distintas. ¿Existen diferencias significativas dependiendo de las condiciones?


```{r echo=TRUE,, message=FALSE}
datos <- data.frame(condicion = c(rep("condicion1", 18), rep("condicion2", 18), rep("condicion3", 18)), n_huevos = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 27, 28, 29, 30, 51, 52, 53, 342, 40, 41, 42, 43, 44, 45, 46, 47, 48, 67, 88, 89, 90, 91, 92, 93, 94, 293, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 25, 36, 37, 58, 59, 60, 71, 72)) 
head(datos)

ggplot(data = datos, mapping = aes(x = condicion, y = n_huevos, colour = condicion)) + 
  geom_boxplot() + theme_bw() + theme(legend.position = "none")

ggplot(data = datos, mapping = aes(x = n_huevos, colour = condicion)) + 
  geom_histogram() + theme_bw() + facet_grid(. ~ condicion) + 
  theme(legend.position = "none")# + stat_bin(binwidth=30)
```
<br>

Aplicamos ANOVA.

```{r echo=TRUE}

aov.datos<-aov(n_huevos~condicion,data=datos)
summary(aov.datos)

```


<br>
<h4>Analizamos los supuestos para la validez de ANOVA (normalidad y homoscedasticidad):</h4>

```{r echo=TRUE}

qqnorm(resid(aov.datos))
qqline(resid(aov.datos))

shapiro.test(residuals(aov.datos))

leveneTest(n_huevos ~ condicion, data = datos)
```
No se cumplen los supuestos para la validez de ANOVA.

<br>
<h4>Una alternativa en caso de que no se cumplan los supuestos para la aplicación de ANOVA ni en los datos originales ni en los transformados:</h4>

```{r echo=TRUE}

kruskal.test(n_huevos ~ condicion, data = datos)

#library(pgirmess)
kruskalmc(datos$n_huevos ~ datos$condicion)

```
<br>

## <span style="color:darkred">ANOVA de 2 factores</span>

<br>

### Ejemplo

Supóngase un estudio clínico que analiza la eficacia de un medicamento teniendo en cuenta dos factores, el sexo (masculino y femenino) y la edad (joven, adulto). Se quiere analizar si el efecto es diferente entre alguno de los niveles de cada variable por si sola o en combinación.

<br>
```{r, echo=TRUE}
individuo <- as.factor(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30)) 
sexo <- c("mujer", "hombre", "hombre", "mujer", "hombre", "hombre", "hombre", "mujer", "mujer", "hombre", "hombre", "hombre", "hombre", "mujer", "mujer", "mujer", "hombre", "mujer", "mujer", "hombre", "hombre", "mujer", "hombre", "hombre", "hombre", "hombre", "hombre", "hombre", "mujer", "hombre") 
edad <- c("adulto", "adulto", "adulto", "adulto", "adulto", "adulto", "joven", "joven", "adulto", "joven", "joven", "adulto", "joven", "joven", "joven", "adulto", "joven", "adulto", "joven", "joven", "joven", "joven", "adulto", "joven", "joven", "joven", "joven", "joven", "joven", "adulto") 
resultado <- c(7.1, 11, 5.8, 8.8, 8.6, 8, 3, 5.2, 3.4, 4, 5.3, 11.3, 4.6, 6.4, 13.5, 4.7, 5.1, 7.3, 9.5, 5.4, 3.7, 6.2, 10, 1.7, 2.9, 3.2, 4.7, 4.9, 9.8, 9.4) 
datos <- data.frame(individuo, sexo, edad, resultado) 
head(datos, 4)
```


Comparamos los resultados según los niveles de ambas categorías.

```{r, echo=TRUE}
library(ggplot2) 
library(gridExtra) 

p1 <- ggplot(data = datos, mapping = aes(x = edad, y = resultado)) + geom_boxplot() + 
  theme_bw() 
p2 <- ggplot(data = datos, mapping = aes(x = sexo, y = resultado)) + geom_boxplot() + 
  theme_bw() 
p3 <- ggplot(data = datos, mapping = aes(x = edad, y = resultado, colour = sexo)) + 
  geom_boxplot() + theme_bw() 
grid.arrange(p1, p2, ncol = 2)

p3
```


Analizamos interacciones.

```{r, echo=TRUE}
with(data = datos, expr = tapply(resultado, sexo, mean))

with(data = datos, expr = tapply(resultado, sexo, sd))

with(data = datos, expr = tapply(resultado, edad, mean))

with(data = datos, expr = tapply(resultado, edad, sd))

with(data = datos, expr = tapply(resultado, list(sexo, edad), mean))

with(data = datos, expr = tapply(resultado, list(sexo, edad), sd))
```

```{r, echo=TRUE}
interaction.plot(trace.factor = datos$sexo, x.factor = datos$edad, response = datos$resultado, fun = "mean", legend = TRUE, col = 2:3, type = "b") 
interaction.plot(trace.factor = datos$edad, x.factor = datos$sexo, response = datos$resultado, fun = "mean", legend = TRUE, col = 2:3, type = "b")
```

```{r, echo=TRUE}
ggplot(data = datos, aes(x = edad, y = resultado, colour = sexo, group = sexo)) + 
  stat_summary(fun.y = mean, geom = "point") + stat_summary(fun.y = mean, geom = "line") + 
  labs(y = "mean (resultado)") + theme_bw()

ggplot(data = datos, aes(x = sexo, y = resultado, colour = edad, group = edad)) + 
  stat_summary(fun.y = mean, geom = "point") + stat_summary(fun.y = mean, geom = "line") + 
  labs(y = "mean (resultado)") + theme_bw()
```

```{r, echo=TRUE}
anova_2vias <- aov(formula = resultado ~ sexo*edad, data = datos) 
summary(anova_2vias)
```

```{r, echo=TRUE}
library(lsr)
etaSquared(anova_2vias)
```

```{r, echo=TRUE}
par(mfrow = c(2,2)) 
plot(anova_2vias)
par(mfrow = c(1,1))
```

La observacion 15 es un outlier según los gráficos anteriores, se podría probar sacarla...


